{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os import path\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from os.path import expanduser, exists\n",
    "\n",
    "from keras.callbacks import LambdaCallback, EarlyStopping,ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, TimeDistributed\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Embedding, Dropout\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "import string\n",
    "\n",
    "\n",
    "% matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "pd.set_option('display.max_colwidth', 300) #widen pandas rows display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16595853631853720265\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 16087777280\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 14993258370002378848\n",
      "physical_device_desc: \"device: 0, name: Quadro P5000, pci bus id: 0000:00:05.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KERAS_DATASETS_DIR = expanduser('~/.keras/datasets/')\n",
    "GLOVE_ZIP_FILE_URL = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n",
    "GLOVE_ZIP_FILE = 'glove.840B.300d.zip'\n",
    "GLOVE_FILE = 'glove.840B.300d.txt'\n",
    "\n",
    "\n",
    "# Model related\n",
    "MAX_NB_WORDS = 15000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q and A average length 74.8691042838598\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27727</th>\n",
       "      <td>Yesterday, the Prime Minister and the public safety minister suggested that the content of that media briefing was classified. Can the Prime Minister inform us who in his office helped orchestrate the release of classified information to the media?</td>\n",
       "      <td>Mr. Speaker, of course, at no point did members of the public service ever reveal classified information to the media, nor would they. The issue is that the Leader of the Opposition so wants to be able to play political games with this issue that he plugs his ears, refuses to know the truth, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27728</th>\n",
       "      <td>The Prime Minister has just affirmed that classified information was not provided to the media. Why, then, can that same information not be provided to the House?</td>\n",
       "      <td>Mr. Speaker, only Stephen Harper's Conservative Party would think that giving information to the media is somehow hiding information from Canadians. The question is: why does the Leader of the Opposition not want to know the truth?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27729</th>\n",
       "      <td>Mr. Speaker, in a healthy and prosperous society, it is essential to ensure that everyone can participate in the economy on a level playing field. Can the Minister of Status of Women tell us what we are doing in budget 2018 to further empower women so that they have equal opportunities to work i...</td>\n",
       "      <td>Mr. Speaker, I thank my colleague from Vimy for her leadership in advancing gender equality. By investing in women, we will improve the economy for everyone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27730</th>\n",
       "      <td>It is unacceptable language. Could the minister please clarify what he was trying to say?</td>\n",
       "      <td>Mr. Speaker, I was at the committee meeting yesterday. It is unfortunate that the opposition members make such personal attacks, when they have an opportunity to discuss budget 2018 and provide constructive criticism.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27731</th>\n",
       "      <td>That is his choice. I have every right to ask questions that make the government uncomfortable and I am going to continue to do it whether those members like it or not.</td>\n",
       "      <td>Mr. Speaker, we often see in the House a type of selective amnesia. I would like to remind the House that the cabinet of the previous prime minister, Stephen Harper, was far from gender-balanced.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                 Q  \\\n",
       "27727                                                     Yesterday, the Prime Minister and the public safety minister suggested that the content of that media briefing was classified. Can the Prime Minister inform us who in his office helped orchestrate the release of classified information to the media?   \n",
       "27728                                                                                                                                           The Prime Minister has just affirmed that classified information was not provided to the media. Why, then, can that same information not be provided to the House?   \n",
       "27729  Mr. Speaker, in a healthy and prosperous society, it is essential to ensure that everyone can participate in the economy on a level playing field. Can the Minister of Status of Women tell us what we are doing in budget 2018 to further empower women so that they have equal opportunities to work i...   \n",
       "27730                                                                                                                                                                                                                    It is unacceptable language. Could the minister please clarify what he was trying to say?   \n",
       "27731                                                                                                                                     That is his choice. I have every right to ask questions that make the government uncomfortable and I am going to continue to do it whether those members like it or not.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                 A  \n",
       "27727  Mr. Speaker, of course, at no point did members of the public service ever reveal classified information to the media, nor would they. The issue is that the Leader of the Opposition so wants to be able to play political games with this issue that he plugs his ears, refuses to know the truth, and...  \n",
       "27728                                                                      Mr. Speaker, only Stephen Harper's Conservative Party would think that giving information to the media is somehow hiding information from Canadians. The question is: why does the Leader of the Opposition not want to know the truth?  \n",
       "27729                                                                                                                                                Mr. Speaker, I thank my colleague from Vimy for her leadership in advancing gender equality. By investing in women, we will improve the economy for everyone.  \n",
       "27730                                                                                    Mr. Speaker, I was at the committee meeting yesterday. It is unfortunate that the opposition members make such personal attacks, when they have an opportunity to discuss budget 2018 and provide constructive criticism.  \n",
       "27731                                                                                                          Mr. Speaker, we often see in the House a type of selective amnesia. I would like to remind the House that the cabinet of the previous prime minister, Stephen Harper, was far from gender-balanced.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Load the training dataset'''\n",
    "\n",
    "q_a_df = pd.read_csv('data/q_a_all.csv')\n",
    "\n",
    "def clean(x):\n",
    "    x = x.replace('BOS', '')\n",
    "    x = x.replace('EOS', '')\n",
    "    return x\n",
    "\n",
    "def text_to_sents(text_seqs):\n",
    "    tokens = re.sub(r'[^\\x00-\\x7f]', u'', text_seqs.lower())\n",
    "    return nltk.sent_tokenize(text_seqs) # this gives us a list of sentences\n",
    "\n",
    "q_a_df['Q'] = q_a_df['Q'].apply(clean)\n",
    "q_a_df['A'] = q_a_df['A'].apply(clean)\n",
    "\n",
    "q_a_df['Q'] = q_a_df['Q'].apply(lambda x: u' '.join(text_to_sents(x)[-2:]))\n",
    "q_a_df['A'] = q_a_df['A'].apply(lambda x: u' '.join(text_to_sents(x)[:2]))\n",
    "\n",
    "total_stories = pd.DataFrame()\n",
    "total_stories['Story'] = q_a_df.apply(lambda x:'%s __EOT__ %s' % (x['Q'], x['A']), axis=1)\n",
    "\n",
    "train_stories = pd.DataFrame(total_stories[:])\n",
    "train_stories.tail()\n",
    "\n",
    "\n",
    "word_count = 0\n",
    "for i, row in train_stories.iterrows():\n",
    "    word_count  += len(row['Story'].split())\n",
    "\n",
    "print('Q and A average length', word_count / len(train_stories))\n",
    "\n",
    "q_a_df[['Q','A']].to_csv('Q_A.tsv', sep='\\t', encoding='utf-8', index=False)\n",
    "q_a_df[['Q','A']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words in Q and A: 2282469\n"
     ]
    }
   ],
   "source": [
    "EOS_token = 'eos'\n",
    "SOS_token = 'sos'\n",
    "UNK_token = '<unk>'\n",
    "NUM_token = '<number>'\n",
    "\n",
    "def text_to_tokens(text_seqs):\n",
    "    tokens = re.sub(r'[^\\x00-\\x7f]', u'', text_seqs)\n",
    "    return nltk.word_tokenize(tokens)\n",
    "                              \n",
    "corpus = []\n",
    "for i, row in q_a_df.iterrows():\n",
    "    corpus.append(text_to_tokens(row['Q']))\n",
    "    corpus.append(text_to_tokens(row['A']))\n",
    "    \n",
    "corpus = [item for sublist in corpus for item in sublist]\n",
    "# print(corpus[:100])\n",
    "print('number of words in Q and A:', len(corpus))\n",
    "\n",
    "from collections import Counter\n",
    "counts = Counter(corpus)\n",
    "# print(counts.most_common(10000))\n",
    "\n",
    "freq_tokens = [SOS_token, EOS_token, UNK_token, NUM_token, '__EOT__'] + list(string.punctuation)\n",
    "for token in counts.most_common(10000):\n",
    "    freq_tokens.append(token[0])\n",
    "    \n",
    "def is_number_repl_isdigit(s):\n",
    "    \"\"\" Returns True is string is a number. \"\"\"\n",
    "    return s.replace('.','',1).isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "df size 3962\n",
      "df size 3962\n",
      "df size 3962\n",
      "df size 3962\n",
      "df size 3961\n",
      "df size 3961\n",
      "df size 3962\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Story</th>\n",
       "      <th>Tokenized_Story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>The minister keeps saying that she is talking to her Quebec counterpart and that she believes in the Canada Health Act. When will she actually enforce it? __EOT__ Mr. Speaker, I thank my colleague for her important question. As I have said, we fully subscribe to the principles of the Canada Heal...</td>\n",
       "      <td>the minister keeps saying that she is talking to her &lt;unk&gt; counterpart and that she believes in the &lt;unk&gt; health act . when will she actually enforce it ? &lt;unk&gt; &lt;unk&gt; speaker , i thank my colleague for her important question . as i have said , we fully &lt;unk&gt; to the principles of the &lt;unk&gt; health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>It is an opportunity to discover the richness of science, technology, engineering, and mathematics in Canada. What is the Government of Canada doing to encourage all Canadians to learn about and to engage with scientific research, and to seriously consider a career in science? __EOT__ Mr. Speake...</td>\n",
       "      <td>it is an opportunity to discover the &lt;unk&gt; of science , technology , engineering , and &lt;unk&gt; in &lt;unk&gt; . what is the government of &lt;unk&gt; doing to encourage all &lt;unk&gt; to learn about and to engage with scientific research , and to seriously consider a career in science ? &lt;unk&gt; &lt;unk&gt; speaker , i wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Now the Ethics Commissioner has ruled that a conflict of interest does exist, and the chief of staff must recuse herself of most major files in the minister's department. If she cannot talk about agriculture, and if she cannot talk about trade, what is she still doing there? __EOT__ Mr. Speaker,...</td>\n",
       "      <td>now the ethics commissioner has ruled that a conflict of interest does exist , and the chief of staff must recuse herself of most major files in the minister 's department . if she can not talk about agriculture , and if she can not talk about trade , what is she still doing there ? &lt;unk&gt; &lt;unk&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>Mr. Speaker, that was the same talking points that he gave to me on January 25, but we found out just recently from the Ethics Commissioner that her new ruling requires that his chief of staff not engage with the TPP, not have any involvement with regard to the egg industry, and have nothing to ...</td>\n",
       "      <td>&lt;unk&gt; speaker , that was the same talking points that he gave to me on &lt;unk&gt; &lt;number&gt; , but we found out just recently from the ethics commissioner that her new ruling requires that his chief of staff not engage with the &lt;unk&gt; , not have any involvement with regard to the egg industry , and have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>The minister refused to listen to us. How can the minister assure farmers and processors that his chief of staff has not been using this job for personal gain? __EOT__ Mr. Speaker, I know the member for Lambton—Kent—Middlesex, and I am surprised that he would indicate that such a competent lady ...</td>\n",
       "      <td>the minister refused to listen to us . how can the minister assure farmers and processors that his chief of staff has not been using this job for personal gain ? &lt;unk&gt; &lt;unk&gt; speaker , i know the member for &lt;unk&gt; , and i am surprised that he would indicate that such a competent &lt;unk&gt; would be in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             Story  \\\n",
       "19995  The minister keeps saying that she is talking to her Quebec counterpart and that she believes in the Canada Health Act. When will she actually enforce it? __EOT__ Mr. Speaker, I thank my colleague for her important question. As I have said, we fully subscribe to the principles of the Canada Heal...   \n",
       "19996  It is an opportunity to discover the richness of science, technology, engineering, and mathematics in Canada. What is the Government of Canada doing to encourage all Canadians to learn about and to engage with scientific research, and to seriously consider a career in science? __EOT__ Mr. Speake...   \n",
       "19997  Now the Ethics Commissioner has ruled that a conflict of interest does exist, and the chief of staff must recuse herself of most major files in the minister's department. If she cannot talk about agriculture, and if she cannot talk about trade, what is she still doing there? __EOT__ Mr. Speaker,...   \n",
       "19998  Mr. Speaker, that was the same talking points that he gave to me on January 25, but we found out just recently from the Ethics Commissioner that her new ruling requires that his chief of staff not engage with the TPP, not have any involvement with regard to the egg industry, and have nothing to ...   \n",
       "19999  The minister refused to listen to us. How can the minister assure farmers and processors that his chief of staff has not been using this job for personal gain? __EOT__ Mr. Speaker, I know the member for Lambton—Kent—Middlesex, and I am surprised that he would indicate that such a competent lady ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                   Tokenized_Story  \n",
       "19995  the minister keeps saying that she is talking to her <unk> counterpart and that she believes in the <unk> health act . when will she actually enforce it ? <unk> <unk> speaker , i thank my colleague for her important question . as i have said , we fully <unk> to the principles of the <unk> health...  \n",
       "19996  it is an opportunity to discover the <unk> of science , technology , engineering , and <unk> in <unk> . what is the government of <unk> doing to encourage all <unk> to learn about and to engage with scientific research , and to seriously consider a career in science ? <unk> <unk> speaker , i wou...  \n",
       "19997  now the ethics commissioner has ruled that a conflict of interest does exist , and the chief of staff must recuse herself of most major files in the minister 's department . if she can not talk about agriculture , and if she can not talk about trade , what is she still doing there ? <unk> <unk> ...  \n",
       "19998  <unk> speaker , that was the same talking points that he gave to me on <unk> <number> , but we found out just recently from the ethics commissioner that her new ruling requires that his chief of staff not engage with the <unk> , not have any involvement with regard to the egg industry , and have...  \n",
       "19999  the minister refused to listen to us . how can the minister assure farmers and processors that his chief of staff has not been using this job for personal gain ? <unk> <unk> speaker , i know the member for <unk> , and i am surprised that he would indicate that such a competent <unk> would be in ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Split texts into lists of words (tokens)'''\n",
    "\n",
    "\n",
    "\n",
    "encoder = spacy.load('en')\n",
    "\n",
    "def text_to_tokens(text_seqs):\n",
    "#     token_seqs = [[word.lower_ for word in encoder(text_seq)] for text_seq in text_seqs]\n",
    "#     return token_seqs\n",
    "    tokens = []\n",
    "    for word in nltk.word_tokenize(text_seqs.lower()):\n",
    "        if word not in freq_tokens:\n",
    "            word = UNK_token\n",
    "        if is_number_repl_isdigit(word):\n",
    "            word = NUM_token\n",
    "        tokens.append(word)\n",
    "    return re.sub(r'[^\\x00-\\x7f]',r'', u' '.join(tokens))\n",
    "\n",
    "def _apply_df(args):\n",
    "    df, func, kwargs = args\n",
    "    print('df size', len(df))\n",
    "    df['Tokenized_Story'] = df['Story'].apply(func, **kwargs)\n",
    "    return df#df.apply(func, **kwargs)\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    workers = kwargs.pop('workers')\n",
    "    pool = multiprocessing.Pool(processes=workers)\n",
    "    result = pool.map(_apply_df, [(d, func, kwargs) for d in np.array_split(df, workers)])\n",
    "    pool.close()\n",
    "    return pd.concat(list(result))\n",
    "\n",
    "num_cores = multiprocessing.cpu_count() - 1\n",
    "print(num_cores) \n",
    "    \n",
    "train_stories = apply_by_multiprocessing(train_stories, text_to_tokens,  workers=num_cores)\n",
    "# \n",
    "# train_stories['Tokenized_Story'] = text_to_tokens(train_stories['Story'])\n",
    "    \n",
    "# Only 20000 records for the training set\n",
    "train_stories = train_stories[:20000]\n",
    "train_stories[['Story','Tokenized_Story']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in index: 7689\n",
      "word_index {'unk': 1, 'the': 2, ',': 3, '.': 4, 'to': 5, 'of': 6, 'and': 7, 'that': 8, 'is': 9, 'in': 10, '?': 11, 'speaker': 12, 'a': 13, 'for': 14, 'we': 15, 'will': 16, 'this': 17, 'government': 18, 'minister': 19, 'are': 20}\n",
      "index_word {1: 'unk', 2: 'the', 3: ',', 4: '.', 5: 'to', 6: 'of', 7: 'and', 8: 'that', 9: 'is', 10: 'in', 11: '?', 12: 'speaker', 13: 'a', 14: 'for', 15: 'we', 16: 'will', 17: 'this', 18: 'government', 19: 'minister', 20: 'are'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS,\n",
    "                      lower=True, split=' ', filters='\"#%&()*+-/<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                      char_level=False, oov_token=u'<UNK>')\n",
    "\n",
    "tokenizer.fit_on_texts(train_stories['Tokenized_Story'].values)\n",
    "q_a_word_sequences = tokenizer.texts_to_sequences(train_stories['Tokenized_Story'].values)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Words in index: %d\" % len(word_index))\n",
    "print('word_index', dict(list(word_index.items())[:20]))\n",
    "\n",
    "index_word = {v: k for k, v in word_index.items()}\n",
    "# Add empty to \n",
    "index_word[0] = '' #map 0 padding to empty string\n",
    "print('index_word', dict(list(index_word.items())[:20]))\n",
    "\n",
    "vocab_size = len(word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing glove.840B.300d.txt\n",
      "Word embeddings: 2196016\n",
      "CPU times: user 2min 21s, sys: 4.24 s, total: 2min 26s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# Run once only\n",
    "if not exists(KERAS_DATASETS_DIR + GLOVE_FILE):\n",
    "    zipfile = ZipFile(get_file(GLOVE_ZIP_FILE, GLOVE_ZIP_FILE_URL))\n",
    "    zipfile.extract(GLOVE_FILE, path=KERAS_DATASETS_DIR)\n",
    "    \n",
    "print(\"Processing\", GLOVE_FILE)\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(KERAS_DATASETS_DIR + GLOVE_FILE, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings: %d' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7689 7689\n",
      "L2 Normalization\n",
      "vocab size 7690\n",
      "Null word embeddings: 5\n",
      "CPU times: user 24 ms, sys: 8 ms, total: 32 ms\n",
      "Wall time: 33.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "print(nb_words, len(word_index))\n",
    "# word_embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
    "embedding_matrix = np.random.uniform(-1, 1, size=(nb_words + 1, EMBEDDING_DIM))\n",
    "count = 0\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector[:EMBEDDING_DIM]\n",
    "        count += 1\n",
    "\n",
    "print('L2 Normalization')\n",
    "\n",
    "# l2-normalize the samples (rows). \n",
    "embedding_matrix = preprocessing.normalize(embedding_matrix, norm='l2')\n",
    "\n",
    "vocab_size = nb_words + 1\n",
    "print('vocab size', vocab_size)\n",
    "print('Null word embeddings: %d' % (vocab_size - count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building....     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "#     print(model_history.history)\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''Create the model'''\n",
    "\n",
    "\n",
    "def GRU_Deep_model(seq_input_len, n_input_nodes, n_embedding_nodes, \n",
    "                 n_hidden_nodes, stateful=False, batch_size=None):\n",
    "\n",
    "    input_layer = Input(batch_shape=(batch_size, seq_input_len), name='input_layer')\n",
    " \n",
    "    embedding_layer = Embedding(vocab_size, EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)(input_layer)\n",
    "\n",
    "    gru_layer1 = GRU(n_hidden_nodes, dropout=0.2,\n",
    "                     recurrent_initializer='he_uniform', kernel_initializer='he_uniform',\n",
    "                     return_sequences=True, #return hidden state for each word, not just last one\n",
    "                     stateful=stateful, name='hidden_layer1')(embedding_layer)\n",
    "\n",
    "    gru_layer2 = GRU(n_hidden_nodes, dropout=0.2,\n",
    "                     recurrent_initializer='he_uniform', kernel_initializer='he_uniform',\n",
    "                     return_sequences=True,\n",
    "                     stateful=stateful, name='hidden_layer2')(gru_layer1)\n",
    "\n",
    "    output_layer = TimeDistributed(Dense(n_input_nodes, activation=\"softmax\"), \n",
    "                                   name='output_layer')(gru_layer2)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    #Specify loss function and optimization algorithm, compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def LSTM_Deep_model(seq_input_len, n_input_nodes, n_embedding_nodes, \n",
    "                 n_hidden_nodes, stateful=False, batch_size=None):\n",
    "\n",
    "    input_layer = Input(batch_shape=(batch_size, seq_input_len), name='input_layer')\n",
    " \n",
    "    embedding_layer = Embedding(vocab_size, EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)(input_layer)\n",
    "    gru_layer1 = LSTM(n_hidden_nodes, dropout=0.2,\n",
    "                     recurrent_initializer='he_uniform', kernel_initializer='he_uniform',\n",
    "                     return_sequences=True, #return hidden state for each word, not just last one\n",
    "                     stateful=stateful, name='hidden_layer1')(embedding_layer)\n",
    "    gru_layer2 = LSTM(n_hidden_nodes, dropout=0.2,\n",
    "                     recurrent_initializer='he_uniform', kernel_initializer='he_uniform',\n",
    "                     return_sequences=True,\n",
    "                     stateful=stateful, name='hidden_layer2')(gru_layer1)\n",
    "    output_layer = TimeDistributed(Dense(n_input_nodes, activation=\"softmax\"), \n",
    "                                   name='output_layer')(gru_layer2)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def LSTM_valina_model(seq_input_len, n_input_nodes, n_embedding_nodes, \n",
    "                 n_hidden_nodes, stateful=False, batch_size=None):\n",
    "    \n",
    "    input_layer = Input(batch_shape=(batch_size, seq_input_len), name='input_layer')  \n",
    "    \n",
    "    embedding_layer = Embedding(vocab_size, EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)(input_layer)\n",
    "    \n",
    "    gru_layer1 = LSTM(n_hidden_nodes, dropout=0.2,\n",
    "                     recurrent_initializer='he_uniform', kernel_initializer='he_uniform',\n",
    "                     return_sequences=True, \n",
    "                     stateful=stateful, name='hidden_layer1')(embedding_layer)\n",
    "    \n",
    "    output_layer = TimeDistributed(Dense(n_input_nodes, activation=\"softmax\"), \n",
    "                                   name='output_layer')(gru_layer1)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def GRU_valina_model(seq_input_len, n_input_nodes, n_embedding_nodes, \n",
    "                 n_hidden_nodes, stateful=False, batch_size=None):\n",
    "    \n",
    "    input_layer = Input(batch_shape=(batch_size, seq_input_len), name='input_layer')  \n",
    "    \n",
    "    embedding_layer = Embedding(vocab_size, EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)(input_layer)\n",
    "    \n",
    "    gru_layer1 = GRU(n_hidden_nodes, dropout=0.2,\n",
    "                     recurrent_initializer='he_uniform', kernel_initializer='he_uniform',\n",
    "                     return_sequences=True, #return hidden state for each word, not just last one\n",
    "                     stateful=stateful, name='hidden_layer1')(embedding_layer)\n",
    "    \n",
    "    output_layer = TimeDistributed(Dense(n_input_nodes, activation=\"softmax\"), \n",
    "                                   name='output_layer')(gru_layer1)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question & answer data tensor: (20000, 101)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Words</th>\n",
       "      <th>Output Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>701</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>200</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Input Words  Output Words\n",
       "95          701             6\n",
       "96            6             8\n",
       "97            8           200\n",
       "98          200           123\n",
       "99          123             4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_a_data_padded = pad_sequences(q_a_word_sequences, \n",
    "                                maxlen=MAX_SEQUENCE_LENGTH + 1)\n",
    "\n",
    "print('Shape of question & answer data tensor:', q_a_data_padded.shape)\n",
    "# print(q_a_data_padded[:,:20])\n",
    "\n",
    "pd.DataFrame(list(zip(q_a_data_padded[0,:-1], q_a_data_padded[0, 1:])),\n",
    "                columns=['Input Words', 'Output Words']).tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (20000, 100)\n",
      "y.shape (20000, 100, 1)\n",
      "(20000, 101)\n"
     ]
    }
   ],
   "source": [
    "'''Train the model'''\n",
    "\n",
    "\n",
    "# define early stopping callback\n",
    "earlystop = EarlyStopping(monitor='loss', patience=2, verbose=1, mode='auto')\n",
    "# checkpoint\n",
    "filepath=\"data/2XGRU-NLG-{epoch:02d}-{loss:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [earlystop]\n",
    "\n",
    "epochs=100\n",
    "batch_size=128\n",
    "\n",
    "x = q_a_data_padded[:,:-1]\n",
    "y = q_a_data_padded[:, 1:, None]\n",
    "\n",
    "\n",
    "# y=train_padded_idxs[:, 1:]\n",
    "print('x.shape', x.shape)\n",
    "print('y.shape', y.shape)\n",
    "print(q_a_data_padded.shape)\n",
    "\n",
    "\n",
    "LSTM_valina = LSTM_valina_model(seq_input_len=q_a_data_padded.shape[-1] - 1, #substract 1 from matrix length because of offset \n",
    "                     n_input_nodes = vocab_size + 1, # Add 1 to account for 0 padding\n",
    "                     n_embedding_nodes = EMBEDDING_DIM,\n",
    "                     n_hidden_nodes = 128)\n",
    "\n",
    "GRU_valina = GRU_valina_model(seq_input_len=q_a_data_padded.shape[-1] - 1, #substract 1 from matrix length because of offset \n",
    "                     n_input_nodes = vocab_size + 1, # Add 1 to account for 0 padding\n",
    "                     n_embedding_nodes = EMBEDDING_DIM,\n",
    "                     n_hidden_nodes = 128)\n",
    "\n",
    "GRU_Deep = GRU_Deep_model(seq_input_len=q_a_data_padded.shape[-1] - 1, #substract 1 from matrix length because of offset \n",
    "                     n_input_nodes = vocab_size + 1, # Add 1 to account for 0 padding\n",
    "                     n_embedding_nodes = EMBEDDING_DIM,\n",
    "                     n_hidden_nodes = 128)\n",
    "\n",
    "LSTM_Deep = LSTM_Deep_model(seq_input_len=q_a_data_padded.shape[-1] - 1, #substract 1 from matrix length because of offset \n",
    "                     n_input_nodes = vocab_size + 1, # Add 1 to account for 0 padding\n",
    "                     n_embedding_nodes = EMBEDDING_DIM,\n",
    "                     n_hidden_nodes = 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# def batch(x, y, n=1000):\n",
    "#     l = len(x)\n",
    "#     while True:\n",
    "#         for ndx in range(0, l, n):\n",
    "#             yield (x[ndx:min(ndx + n, l)], y[ndx:min(ndx + n, l)])\n",
    "#         break\n",
    "        \n",
    "# for X_batch, Y_batch in batch(x, y, 500):\n",
    "#     print (X_batch.shape, Y_batch.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* GRU_Deep_model *************************\n",
      "File path of model weights:  data/q_a_only_GRU_Deep_model_weights.h5\n",
      ".h5 file not found\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 100, 100)          769000    \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (GRU)          (None, 100, 128)          87936     \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (GRU)          (None, 100, 128)          98688     \n",
      "_________________________________________________________________\n",
      "output_layer (TimeDistribute (None, 100, 7691)         992139    \n",
      "=================================================================\n",
      "Total params: 1,947,763\n",
      "Trainable params: 1,947,763\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 19000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "19000/19000 [==============================] - 57s 3ms/step - loss: 4.8602 - acc: 0.2817 - val_loss: 4.2738 - val_acc: 0.3234\n",
      "Epoch 2/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 3.9861 - acc: 0.3582 - val_loss: 3.7855 - val_acc: 0.3703\n",
      "Epoch 3/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 3.6602 - acc: 0.3895 - val_loss: 3.5587 - val_acc: 0.3989\n",
      "Epoch 4/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 3.4782 - acc: 0.4123 - val_loss: 3.4237 - val_acc: 0.4172\n",
      "Epoch 5/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 3.3598 - acc: 0.4263 - val_loss: 3.3318 - val_acc: 0.4257\n",
      "Epoch 6/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 3.2745 - acc: 0.4350 - val_loss: 3.2641 - val_acc: 0.4355\n",
      "Epoch 7/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 3.2084 - acc: 0.4415 - val_loss: 3.2162 - val_acc: 0.4406\n",
      "Epoch 8/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 3.1550 - acc: 0.4469 - val_loss: 3.1762 - val_acc: 0.4460\n",
      "Epoch 9/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 3.1108 - acc: 0.4510 - val_loss: 3.1429 - val_acc: 0.4492\n",
      "Epoch 10/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 3.0728 - acc: 0.4545 - val_loss: 3.1177 - val_acc: 0.4488\n",
      "Epoch 11/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 3.0396 - acc: 0.4577 - val_loss: 3.0924 - val_acc: 0.4526\n",
      "Epoch 12/100\n",
      "19000/19000 [==============================] - 55s 3ms/step - loss: 3.0103 - acc: 0.4604 - val_loss: 3.0744 - val_acc: 0.4555\n",
      "Epoch 13/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.9834 - acc: 0.4630 - val_loss: 3.0525 - val_acc: 0.4572\n",
      "Epoch 14/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.9597 - acc: 0.4653 - val_loss: 3.0398 - val_acc: 0.4592\n",
      "Epoch 15/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.9377 - acc: 0.4674 - val_loss: 3.0261 - val_acc: 0.4591\n",
      "Epoch 16/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.9176 - acc: 0.4692 - val_loss: 3.0126 - val_acc: 0.4610\n",
      "Epoch 17/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.8997 - acc: 0.4705 - val_loss: 3.0039 - val_acc: 0.4609\n",
      "Epoch 18/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.8825 - acc: 0.4721 - val_loss: 2.9910 - val_acc: 0.4641\n",
      "Epoch 19/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.8666 - acc: 0.4736 - val_loss: 2.9836 - val_acc: 0.4632\n",
      "Epoch 20/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.8519 - acc: 0.4749 - val_loss: 2.9734 - val_acc: 0.4636\n",
      "Epoch 21/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.8383 - acc: 0.4759 - val_loss: 2.9666 - val_acc: 0.4645\n",
      "Epoch 22/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.8252 - acc: 0.4773 - val_loss: 2.9581 - val_acc: 0.4658\n",
      "Epoch 23/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.8133 - acc: 0.4780 - val_loss: 2.9514 - val_acc: 0.4676\n",
      "Epoch 24/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.8016 - acc: 0.4789 - val_loss: 2.9422 - val_acc: 0.4685\n",
      "Epoch 25/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.7907 - acc: 0.4802 - val_loss: 2.9379 - val_acc: 0.4686\n",
      "Epoch 26/100\n",
      "19000/19000 [==============================] - 55s 3ms/step - loss: 2.7807 - acc: 0.4812 - val_loss: 2.9345 - val_acc: 0.4675\n",
      "Epoch 27/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.7712 - acc: 0.4820 - val_loss: 2.9270 - val_acc: 0.4684\n",
      "Epoch 28/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.7620 - acc: 0.4827 - val_loss: 2.9253 - val_acc: 0.4693\n",
      "Epoch 29/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.7524 - acc: 0.4835 - val_loss: 2.9183 - val_acc: 0.4710\n",
      "Epoch 30/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.7444 - acc: 0.4842 - val_loss: 2.9129 - val_acc: 0.4706\n",
      "Epoch 31/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.7365 - acc: 0.4849 - val_loss: 2.9113 - val_acc: 0.4710\n",
      "Epoch 32/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.7290 - acc: 0.4858 - val_loss: 2.9071 - val_acc: 0.4724\n",
      "Epoch 33/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.7209 - acc: 0.4864 - val_loss: 2.9064 - val_acc: 0.4701\n",
      "Epoch 34/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 2.7143 - acc: 0.4870 - val_loss: 2.8991 - val_acc: 0.4722\n",
      "Epoch 35/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 2.7077 - acc: 0.4874 - val_loss: 2.8986 - val_acc: 0.4712\n",
      "Epoch 36/100\n",
      "19000/19000 [==============================] - 51s 3ms/step - loss: 2.7015 - acc: 0.4879 - val_loss: 2.8949 - val_acc: 0.4731\n",
      "Epoch 37/100\n",
      "19000/19000 [==============================] - 51s 3ms/step - loss: 2.6949 - acc: 0.4885 - val_loss: 2.8959 - val_acc: 0.4716\n",
      "Epoch 38/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 2.6893 - acc: 0.4889 - val_loss: 2.8899 - val_acc: 0.4734\n",
      "Epoch 39/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 2.6838 - acc: 0.4894 - val_loss: 2.8892 - val_acc: 0.4738\n",
      "Epoch 40/100\n",
      "19000/19000 [==============================] - 51s 3ms/step - loss: 2.6778 - acc: 0.4900 - val_loss: 2.8870 - val_acc: 0.4723\n",
      "Epoch 41/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 2.6728 - acc: 0.4905 - val_loss: 2.8836 - val_acc: 0.4729\n",
      "Epoch 42/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 2.6670 - acc: 0.4909 - val_loss: 2.8827 - val_acc: 0.4730\n",
      "Epoch 43/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.6624 - acc: 0.4913 - val_loss: 2.8786 - val_acc: 0.4754\n",
      "Epoch 44/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.6574 - acc: 0.4920 - val_loss: 2.8777 - val_acc: 0.4752\n",
      "Epoch 45/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.6522 - acc: 0.4922 - val_loss: 2.8769 - val_acc: 0.4738\n",
      "Epoch 46/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.6478 - acc: 0.4927 - val_loss: 2.8743 - val_acc: 0.4747\n",
      "Epoch 47/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.6429 - acc: 0.4931 - val_loss: 2.8711 - val_acc: 0.4759\n",
      "Epoch 48/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 2.6386 - acc: 0.4938 - val_loss: 2.8678 - val_acc: 0.4771\n",
      "Epoch 49/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.6343 - acc: 0.4939 - val_loss: 2.8718 - val_acc: 0.4757\n",
      "Epoch 50/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.6301 - acc: 0.4945 - val_loss: 2.8689 - val_acc: 0.4758\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.6261 - acc: 0.4948 - val_loss: 2.8700 - val_acc: 0.4754\n",
      "Epoch 52/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.6222 - acc: 0.4951 - val_loss: 2.8657 - val_acc: 0.4766\n",
      "Epoch 53/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.6179 - acc: 0.4953 - val_loss: 2.8639 - val_acc: 0.4767\n",
      "Epoch 54/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.6142 - acc: 0.4958 - val_loss: 2.8635 - val_acc: 0.4770\n",
      "Epoch 55/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.6104 - acc: 0.4961 - val_loss: 2.8609 - val_acc: 0.4753\n",
      "Epoch 56/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.6074 - acc: 0.4965 - val_loss: 2.8603 - val_acc: 0.4757\n",
      "Epoch 57/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.6037 - acc: 0.4965 - val_loss: 2.8614 - val_acc: 0.4764\n",
      "Epoch 58/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.6005 - acc: 0.4972 - val_loss: 2.8600 - val_acc: 0.4769\n",
      "Epoch 59/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.5964 - acc: 0.4974 - val_loss: 2.8571 - val_acc: 0.4764\n",
      "Epoch 60/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5933 - acc: 0.4973 - val_loss: 2.8572 - val_acc: 0.4784\n",
      "Epoch 61/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5902 - acc: 0.4977 - val_loss: 2.8567 - val_acc: 0.4778\n",
      "Epoch 62/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.5881 - acc: 0.4980 - val_loss: 2.8582 - val_acc: 0.4783\n",
      "Epoch 63/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 2.5836 - acc: 0.4983 - val_loss: 2.8558 - val_acc: 0.4765\n",
      "Epoch 64/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 2.5817 - acc: 0.4986 - val_loss: 2.8517 - val_acc: 0.4778\n",
      "Epoch 65/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5787 - acc: 0.4988 - val_loss: 2.8559 - val_acc: 0.4777\n",
      "Epoch 66/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5763 - acc: 0.4988 - val_loss: 2.8529 - val_acc: 0.4791\n",
      "Epoch 67/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 2.5733 - acc: 0.4990 - val_loss: 2.8539 - val_acc: 0.4789\n",
      "Epoch 68/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5708 - acc: 0.4993 - val_loss: 2.8508 - val_acc: 0.4780\n",
      "Epoch 69/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5679 - acc: 0.4997 - val_loss: 2.8523 - val_acc: 0.4783\n",
      "Epoch 70/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5649 - acc: 0.5000 - val_loss: 2.8514 - val_acc: 0.4790\n",
      "Epoch 71/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5625 - acc: 0.5001 - val_loss: 2.8512 - val_acc: 0.4778\n",
      "Epoch 72/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5606 - acc: 0.5004 - val_loss: 2.8524 - val_acc: 0.4773\n",
      "Epoch 73/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5574 - acc: 0.5005 - val_loss: 2.8486 - val_acc: 0.4782\n",
      "Epoch 74/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5549 - acc: 0.5007 - val_loss: 2.8526 - val_acc: 0.4791\n",
      "Epoch 75/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5538 - acc: 0.5008 - val_loss: 2.8499 - val_acc: 0.4774\n",
      "Epoch 76/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5512 - acc: 0.5012 - val_loss: 2.8496 - val_acc: 0.4772\n",
      "Epoch 77/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5486 - acc: 0.5013 - val_loss: 2.8497 - val_acc: 0.4785\n",
      "Epoch 78/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 2.5465 - acc: 0.5018 - val_loss: 2.8471 - val_acc: 0.4786\n",
      "Epoch 79/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5441 - acc: 0.5017 - val_loss: 2.8479 - val_acc: 0.4777\n",
      "Epoch 80/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5419 - acc: 0.5020 - val_loss: 2.8484 - val_acc: 0.4779\n",
      "Epoch 81/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5396 - acc: 0.5020 - val_loss: 2.8447 - val_acc: 0.4796\n",
      "Epoch 82/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.5387 - acc: 0.5021 - val_loss: 2.8471 - val_acc: 0.4787\n",
      "Epoch 83/100\n",
      "19000/19000 [==============================] - 54s 3ms/step - loss: 2.5365 - acc: 0.5022 - val_loss: 2.8456 - val_acc: 0.4779\n",
      "Epoch 84/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5344 - acc: 0.5022 - val_loss: 2.8490 - val_acc: 0.4774\n",
      "Epoch 85/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5323 - acc: 0.5027 - val_loss: 2.8485 - val_acc: 0.4787\n",
      "Epoch 86/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5304 - acc: 0.5029 - val_loss: 2.8470 - val_acc: 0.4790\n",
      "Epoch 87/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5287 - acc: 0.5032 - val_loss: 2.8440 - val_acc: 0.4783\n",
      "Epoch 88/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5267 - acc: 0.5033 - val_loss: 2.8456 - val_acc: 0.4790\n",
      "Epoch 89/100\n",
      "19000/19000 [==============================] - 52s 3ms/step - loss: 2.5254 - acc: 0.5034 - val_loss: 2.8442 - val_acc: 0.4798\n",
      "Epoch 90/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5235 - acc: 0.5038 - val_loss: 2.8452 - val_acc: 0.4795\n",
      "Epoch 91/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5221 - acc: 0.5036 - val_loss: 2.8421 - val_acc: 0.4799\n",
      "Epoch 92/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5201 - acc: 0.5038 - val_loss: 2.8449 - val_acc: 0.4789\n",
      "Epoch 93/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5186 - acc: 0.5039 - val_loss: 2.8442 - val_acc: 0.4794\n",
      "Epoch 94/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5176 - acc: 0.5040 - val_loss: 2.8423 - val_acc: 0.4794\n",
      "Epoch 95/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5153 - acc: 0.5042 - val_loss: 2.8431 - val_acc: 0.4802\n",
      "Epoch 96/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5138 - acc: 0.5043 - val_loss: 2.8434 - val_acc: 0.4786\n",
      "Epoch 97/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5130 - acc: 0.5043 - val_loss: 2.8432 - val_acc: 0.4810\n",
      "Epoch 98/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5117 - acc: 0.5043 - val_loss: 2.8441 - val_acc: 0.4776\n",
      "Epoch 99/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5103 - acc: 0.5045 - val_loss: 2.8426 - val_acc: 0.4783\n",
      "Epoch 100/100\n",
      "19000/19000 [==============================] - 53s 3ms/step - loss: 2.5080 - acc: 0.5049 - val_loss: 2.8443 - val_acc: 0.4783\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA44AAAFbCAYAAACam9AhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRC6xcCQiIiIiIiKXWDgSERERERGRS/8HVmHF+dLlXTEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf99157160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_list = {\n",
    "   # 'LSTM_valina_model' : LSTM_valina, 'GRU_valina_model' : GRU_valina,\n",
    "    'GRU_Deep_model': GRU_Deep,# 'LSTM_Deep_model' : LSTM_Deep\n",
    "             }\n",
    "\n",
    "for name, model in model_list.items():\n",
    "\n",
    "    print('*' * 25, name, '*' * 25)\n",
    "    # Check if weights file exists, should not exist only for first run\n",
    "    file_path = 'data/q_a_only_%s_weights.h5' % name\n",
    "    print ('File path of model weights: ', file_path)\n",
    "    if path.isfile(file_path):\n",
    "        print ('found file, loading weights... ')\n",
    "        model.load_weights(file_path)\n",
    "    else:\n",
    "        print ('.h5 file not found')\n",
    "   \n",
    "    model.summary()\n",
    "    #     output matrix (y) has extra 3rd dimension added because sparse cross-entropy function requires one label per row\n",
    "    model_info = model.fit(x, y, verbose=1,\n",
    "              validation_split=0.05, callbacks=callbacks_list, \n",
    "              epochs=epochs, batch_size=batch_size)\n",
    "#     model_info = model.fit_generator(batch(x, y, 500), steps_per_epoch=100, epochs=1)   \n",
    "    model.save_weights(file_path) #Save model\n",
    "#     model_info_list[name] = model_info.history\n",
    "    plot_model_history(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_word[3480]\n",
    "word_index['?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Create a new test model, setting batch_size = 1, seq_input_len = 1, and stateful = True'''\n",
    "\n",
    "# Load lexicon from the saved model \n",
    "# with open('data/lexicon.pkl', 'rb') as f:\n",
    "#     lexicon = pickle.load(f)\n",
    "# lexicon_lookup = get_lexicon_lookup(lexicon)\n",
    "\n",
    "predictor_model = GRU_Deep_model(seq_input_len=1,\n",
    "                               n_input_nodes=vocab_size + 1,\n",
    "                               n_embedding_nodes = EMBEDDING_DIM,\n",
    "                               n_hidden_nodes = 128,\n",
    "                               stateful=True, \n",
    "                               batch_size = 1)\n",
    "\n",
    "predictor_model.load_weights('data/q_a_only_GRU_Deep_model_weights.h5') #Load weights from saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.2: 'unk unk speaker , i am pleased to inform the house that we have been very clear that the unk are in charge of the unk government , and we are trying to make sure that unk are unk and unk . we have been very clear that we have been very clear that we have a strong record of the unk government .',\n",
       " 0.4: \"unk unk speaker , we have been very clear that we have made sure that we have a strong record of accountability and that we have been clear . that is why we have made significant investments in the unk coast guard and unk 's unk to ensure that the unk are safe and secure .\",\n",
       " 0.6: \"unk unk speaker , we are keeping our streets and communities safe . we are pleased to see that this government is focused on what matters to unk 's economy .\",\n",
       " 0.8: \"unk unk speaker , this is a common practice with respect to asylum seekers , and we have asked them to do that , but they should be able to engage in the time to participate in the unk involving the unk . so , did the unk the unk in any way did a decade ago , or for the prime minister 's office if it was its current unk party , that passed it , the commissioner of unk unk council 's expenses , or unk the auditor general said that the election campaign against the integrity of that audit , the opposition still proposes bill unk , and that is before the courts , and i had something to be .\",\n",
       " 1: \"if not , when will the minister of public safety tell parliament what is all in it were inadequate and secure today , as a result of this issue , and will he get the proper transparency from the previous liberal government ? unk unk speaker , unk 's places not to defend the people and unk unk and unk who did not get caught in favour .\",\n",
       " 1.2: \"when will the government stop predecessor playing and , why conduct reviews by making taxes over once again , which is just perhaps done that we can used that promise ? unk unk speaker , as i explained earlier today we learned they of our unk unk on unk 's north that is how all unk were made .\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def text_to_tokens(text_seqs):\n",
    "    tokens = nltk.word_tokenize(text_seqs.lower())\n",
    "    return re.sub(r'[^\\x00-\\x7f]',r'', u' '.join(tokens)).split()\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def generate_ending(idx_seq, diversity=1.0):\n",
    "    \n",
    "    end_of_sent_tokens = [\".\", \"!\", \"?\"]\n",
    "    generated_ending = []\n",
    "    \n",
    "    # First just read initial story, no output needed\n",
    "    for word in idx_seq:\n",
    "        p_next_word = predictor_model.predict(np.array(word)[None,None])[0,0]\n",
    "        \n",
    "    count = 0\n",
    "    number_of_sents = 0\n",
    "    # Now start predicting new words\n",
    "#     while not generated_ending or index_word[next_word] not in end_of_sent_tokens:\n",
    "    while True:\n",
    "#         print('hereee')\n",
    "        next_word = sample(p_next_word, diversity)\n",
    "        #Randomly sample a word from the current probability distribution\n",
    "#         next_word = np.random.choice(a=p_next_word.shape[-1], p=p_next_word)\n",
    "#         print(next_word)\n",
    "        # Append sampled word to generated ending\n",
    "        generated_ending.append(next_word)\n",
    "        \n",
    "        # Get probabilities for next word by inputing sampled word\n",
    "        p_next_word = predictor_model.predict(np.array(next_word)[None,None])[0,0]\n",
    "        \n",
    "        if index_word[next_word] in end_of_sent_tokens:\n",
    "            number_of_sents += 1\n",
    "            \n",
    "        if number_of_sents == 2:\n",
    "            break\n",
    "        \n",
    "        if next_word == 0:\n",
    "            count += 1\n",
    "        if count == 10:\n",
    "            break \n",
    "    \n",
    "    predictor_model.reset_states() #reset hidden state after generating ending\n",
    "    \n",
    "    return u' '.join([index_word[word] if word in index_word else \"\"\n",
    "                                 for word in generated_ending]) #decode from numbers back into words\n",
    "    \n",
    "\n",
    "\n",
    "def gen_chat_response(text):\n",
    "\n",
    "#     print(text)\n",
    "    text_tokens = text_to_tokens(text)        \n",
    "#     print(text_tokens)\n",
    "    \n",
    "    tokens_idxs = tokenizer.texts_to_sequences(text_tokens)\n",
    "    tokens_idxs = [item for sublist in tokens_idxs for item in sublist]\n",
    "#     print(tokens_idxs)\n",
    "#     for diversity in [0.2]:\n",
    "    responses = {}\n",
    "    for diversity in [0.2,0.4, 0.6, 0.8, 1, 1.2]:\n",
    "        generated_ending = generate_ending(tokens_idxs, diversity)\n",
    "        responses[diversity] = generated_ending\n",
    "#         print(\"Text:\", diversity, generated_ending, \"\\n\")\n",
    "    \n",
    "    return responses\n",
    "        \n",
    "\n",
    "text = 'liberal refuee plan?'\n",
    "gen_chat_response(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b2a41760c4af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_chat_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-a811c89ddcc5>\u001b[0m in \u001b[0;36mgen_chat_response\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdiversity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mgenerated_ending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_ending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mresponses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiversity\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_ending\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m#         print(\"Text:\", diversity, generated_ending, \"\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-a811c89ddcc5>\u001b[0m in \u001b[0;36mgenerate_ending\u001b[0;34m(idx_seq, diversity)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Get probabilities for next word by inputing sampled word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mp_next_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mend_of_sent_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1833\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1835\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m       \u001b[0mfeeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m       \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_name_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_name_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1284\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m       \u001b[0mfeeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m       \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_name_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_name_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     58\u001b[0m   \"\"\"\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def text_to_sents(text_seqs):\n",
    "    tokens = nltk.word_tokenize(text_seqs.lower())\n",
    "    return re.sub(r'[^\\x00-\\x7f]',r'', u' '.join(tokens)).split()\n",
    "\n",
    "df = pd.read_csv('NLG_Hansard_generated_responses.tsv', sep='\\t')\n",
    "\n",
    "response = []\n",
    "for i, row in df.iterrows():\n",
    "    responses = gen_chat_response(row['Q'])\n",
    "    response.append(responses)  \n",
    "    \n",
    "print(response)\n",
    "\n",
    "df = df.join(pd.DataFrame(response))\n",
    "\n",
    "df.to_csv('NLG_Hansard_generated_responses.tsv', sep='\\t')\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
